# ğŸš€ RAG Template â€“ FastAPI + LangChain + PGVector

A **production-ready Retrieval-Augmented Generation (RAG)** template built with **FastAPI**, **LangChain**, and **PostgreSQL + PGVector**.  
This project provides a clean architecture for building LLM-powered applications with scalable vector search, modular pipelines, and easy deployment via Docker and Nginx.

---

## ğŸŒŸ Features

- ğŸ” **RAG Architecture** â€“ Combines vector retrieval + LLM generation  
- ğŸ§© **Modular Pipelines** â€“ Embedding, retrieval, and generation separated cleanly  
- ğŸ—ƒï¸ **PGVector Integration** â€“ Store and search embeddings in PostgreSQL  
- âš¡ **FastAPI Backend** â€“ High-performance async API for LLM apps  
- ğŸ› ï¸ **Dockerized Deployment** â€“ Ready-to-run with Nginx reverse proxy  
- ğŸ§± **Domain-Driven Design (DDD)** â€“ Maintainable, scalable codebase  
- ğŸ“Š **Observability Ready** â€“ Easily integrate with Langfuse / LangWatch / Prometheus  

---

## ğŸ§° Tech Stack

| Layer | Technology |
|--------|-------------|
| Backend API | [FastAPI](https://fastapi.tiangolo.com/) |
| LLM Framework | [LangChain](https://www.langchain.com/) |
| Vector DB | [PGVector](https://github.com/pgvector/pgvector) |
| Containerization | Docker + Docker Compose |
| Reverse Proxy | Nginx |
| Scheduler | APScheduler (async) |
| Monitoring | Optional: Langfuse, LangWatch |

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/baocong130899/rag.git
cd rag
git checkout develop
```

### 2ï¸âƒ£ Setup environment
Create `.env` file:
```bash
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=ragdb
OPENAI_API_KEY=your_openai_api_key
JWT_SECRET=your_secret
```

### 3ï¸âƒ£ Run with Docker
```bash
docker-compose up -d --build
```

API available at â†’ [http://localhost:8000](http://localhost:8000)

---

## ğŸ§  Project Structure

```
rag/
â”œâ”€â”€ pipelines/
â”‚   â”œâ”€â”€ embedding_pipeline.py
â”‚   â”œâ”€â”€ retrieval_pipeline.py
â”‚   â””â”€â”€ generation_pipeline.py
â”‚
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ vector_service.py
â”‚   â”œâ”€â”€ document_service.py
â”‚   â””â”€â”€ llm_service.py
â”‚
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ routers/
â”‚   â””â”€â”€ main.py
â”‚
â””â”€â”€ config/
    â”œâ”€â”€ settings.py
    â”œâ”€â”€ logger.py
    â””â”€â”€ db.py
```

---

## ğŸ“¡ API Endpoints (Examples)

| Endpoint | Method | Description |
|-----------|--------|-------------|
| `/api/v1/embed` | POST | Store document embeddings |
| `/api/v1/query` | POST | Retrieve and generate answer |
| `/api/v1/health` | GET | Health check endpoint |

---

## ğŸŒ Deployment

### ğŸ³ Docker Compose
This template includes:
- **FastAPI service**
- **PostgreSQL + PGVector**
- **Nginx reverse proxy** (CORS, HTTPS-ready)

### ğŸ” Reverse Proxy Example
```nginx
add_header 'Access-Control-Allow-Origin' '*' always;
add_header 'Access-Control-Allow-Methods' 'GET, POST, PUT, DELETE, OPTIONS' always;
add_header 'Access-Control-Allow-Headers' 'Authorization, Content-Type' always;
```

---

## ğŸ§© Integration with Langfuse / LangWatch

You can integrate monitoring easily:
```bash
pip install langfuse
```
Then wrap pipelines to track LLM calls, latency, and cost.

---

## ğŸ“ˆ Future Roadmap

- [ ] Add Hybrid Search (BM25 + Vector)
- [ ] Add Authentication (JWT-based)
- [ ] Integrate OpenTelemetry tracing
- [ ] Add Streamlit frontend demo
- [ ] Add test coverage

---

## ğŸ·ï¸ Topics

`rag`, `fastapi`, `langchain`, `pgvector`, `llm`,  
`retrieval-augmented-generation`, `vector-database`,  
`docker`, `nginx`, `openai`, `ai-backend`, `mlops`,  
`langfuse`, `langwatch`, `python`, `chatbot`, `template`

---

## ğŸªª License

Distributed under the MIT License. See `LICENSE` for more information.

---

## ğŸ’« Author

**LÃª CÃ´ng**  
GitHub: [@baocong130899](https://github.com/baocong130899)  
Email: lecong.dev@gmail.com  

---

## â­ Support

If you find this project useful, please **star** ğŸŒŸ the repository and consider contributing!
